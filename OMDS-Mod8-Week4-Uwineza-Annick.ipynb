{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md413FzAvFD8"
      },
      "source": [
        "# DX 704 Week 4 Project\n",
        "\n",
        "This week's project will test the learning speed of linear contextual bandits compared to unoptimized approaches.\n",
        "You will start with building a preference data set for evaluation, and then implement different variations of LinUCB and visualize how fast they learn the preferences.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3gs-tquuzJe"
      },
      "source": [
        "The full project description, a template notebook and supporting code are available on GitHub: [Project 4 Materials](https://github.com/bu-cds-dx704/dx704-project-04).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OguIjc5idW3Z"
      },
      "source": [
        "## Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8oSLkMqvMFF"
      },
      "source": [
        "## Part 1: Collect Rating Data\n",
        "\n",
        "The file \"recipes.tsv\" in this repository has information about 100 recipes.\n",
        "Make a new file \"ratings.tsv\" with two columns, recipe_slug (from recipes.tsv) and rating.\n",
        "Populate the rating column with values between 0 and 1 where 0 is the worst and 1 is the best.\n",
        "You can assign these ratings however you want within that range, but try to make it reflect a consistent set of preferences.\n",
        "These could be your preferences, or a persona of your choosing (e.g. chocolate lover, bacon-obsessed, or sweet tooth).\n",
        "Make sure that there are at least 10 ratings of zero and at least 10 ratings of one.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAwViBgKfWER"
      },
      "source": [
        "Hint: You may find it more convenient to assign raw ratings from 1 to 5 and then remap them as follows.\n",
        "\n",
        "`ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas\n",
            "  Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (79 kB)\n",
            "Collecting numpy>=1.26.0 (from pandas)\n",
            "  Downloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pandas-3.0.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.4.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [pandas]2m1/2\u001b[0m [pandas]\n",
            "\u001b[1A\u001b[2KSuccessfully installed numpy-2.4.2 pandas-3.0.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Saved ratings.tsv\n",
            "Zeros: 16\n",
            "Ones: 26\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "recipes = pd.read_csv(\"recipes.tsv\", sep=\"\\t\")\n",
        "tags = pd.read_csv(\"recipe-tags.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Merge tags into a single text field per recipe\n",
        "tags_agg = tags.groupby(\"recipe_slug\")[\"recipe_tag\"].apply(lambda x: \" \".join(x.astype(str))).reset_index()\n",
        "df = recipes.merge(tags_agg, on=\"recipe_slug\", how=\"left\")\n",
        "\n",
        "# Combine text fields for keyword scoring\n",
        "df[\"text\"] = (\n",
        "    df[\"recipe_title\"].fillna(\"\") + \" \" +\n",
        "    df[\"recipe_introduction\"].fillna(\"\") + \" \" +\n",
        "    df[\"recipe_tag\"].fillna(\"\")\n",
        ").str.lower()\n",
        "\n",
        "# Sweet-tooth persona keywords\n",
        "loves = [\n",
        "    \"chocolate\", \"brownie\", \"cookie\", \"cake\", \"cupcake\", \"muffin\",\n",
        "    \"pancake\", \"waffle\", \"pie\", \"tart\", \"cinnamon\", \"vanilla\",\n",
        "    \"strawberry\", \"blueberry\", \"raspberry\", \"banana\", \"apple\",\n",
        "    \"honey\", \"caramel\", \"ice cream\", \"dessert\", \"sweet\"\n",
        "]\n",
        "hates = [\n",
        "    \"anchovy\", \"sardine\", \"liver\", \"brussels\", \"kale\", \"beet\",\n",
        "    \"spicy\", \"jalape\", \"chili\", \"hot sauce\", \"curry\",\n",
        "    \"tofu\", \"mushroom\", \"broccoli\"\n",
        "]\n",
        "\n",
        "# Score recipes\n",
        "score = pd.Series(0, index=df.index)\n",
        "\n",
        "for kw in loves:\n",
        "    score += df[\"text\"].str.contains(kw).astype(int) * 2\n",
        "\n",
        "for kw in hates:\n",
        "    score -= df[\"text\"].str.contains(kw).astype(int) * 2\n",
        "\n",
        "# Convert score to raw ratings 1–5\n",
        "rating_raw = pd.cut(\n",
        "    score,\n",
        "    bins=[-999, -2, 0, 2, 5, 999],\n",
        "    labels=[1, 2, 3, 4, 5]\n",
        ").astype(int)\n",
        "\n",
        "ratings = pd.DataFrame({\n",
        "    \"recipe_slug\": df[\"recipe_slug\"],\n",
        "    \"rating_raw\": rating_raw\n",
        "})\n",
        "\n",
        "# Force at least 10 zeros (raw=1) and 10 ones (raw=5)\n",
        "need_zeros = max(0, 10 - (ratings[\"rating_raw\"] == 1).sum())\n",
        "need_ones  = max(0, 10 - (ratings[\"rating_raw\"] == 5).sum())\n",
        "\n",
        "if need_zeros > 0:\n",
        "    idx = score.sort_values().head(need_zeros).index\n",
        "    ratings.loc[idx, \"rating_raw\"] = 1\n",
        "\n",
        "if need_ones > 0:\n",
        "    idx = score.sort_values(ascending=False).head(need_ones).index\n",
        "    ratings.loc[idx, \"rating_raw\"] = 5\n",
        "\n",
        "# Map raw ratings to [0, 1]\n",
        "ratings[\"rating\"] = (ratings[\"rating_raw\"] - 1) * 0.25\n",
        "\n",
        "# Sanity checks\n",
        "assert ratings[\"rating\"].between(0, 1).all()\n",
        "assert (ratings[\"rating\"] == 0).sum() >= 10\n",
        "assert (ratings[\"rating\"] == 1).sum() >= 10\n",
        "\n",
        "# Save final file\n",
        "ratings[[\"recipe_slug\", \"rating\"]].to_csv(\"ratings.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved ratings.tsv\")\n",
        "print(\"Zeros:\", (ratings[\"rating\"] == 0).sum())\n",
        "print(\"Ones:\", (ratings[\"rating\"] == 1).sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eh7UaX6OvuWo"
      },
      "source": [
        "Submit \"ratings.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiCwaZwr5M67"
      },
      "source": [
        "## Part 2: Construct Model Input\n",
        "\n",
        "Use your file \"ratings.tsv\" combined with \"recipe-tags.tsv\" to create a new file \"features.tsv\" with a column recipe_slug, a column bias which is hard-coded to one, and a column for each tag that appears in \"recipe-tags.tsv\".\n",
        "The tag column in this file should be a 0-1 encoding of the recipe tags for each recipe.\n",
        "[Pandas reshaping function methods](https://pandas.pydata.org/docs/user_guide/reshaping.html) may be helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WWi_JJXocEb"
      },
      "source": [
        "The bias column will make later LinUCB calculations easier since it will just be another dimension. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHR-BsD9539j"
      },
      "source": [
        "Hint: For later modeling steps, it will be important to have the feature data (inputs) and the rating data (target outputs) in the same order.\n",
        "It is highly recommended to make sure that \"features.tsv\" and \"ratings.tsv\" have the recipe slugs in the same order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cGvj258d8nnv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved features.tsv\n",
            "Shape: (100, 298)\n",
            "        recipe_slug  bias  alfredo  almond  american  appetizer  appetizers  \\\n",
            "0           falafel     1        0       0         0          1           0   \n",
            "1        spamburger     1        0       0         0          0           0   \n",
            "2  bacon-fried-rice     1        0       0         0          0           0   \n",
            "3   chicken-fingers     1        0       0         0          1           0   \n",
            "4       apple-crisp     1        0       0         0          0           0   \n",
            "\n",
            "   apple  asiancuisine  asparagus  ...  udonnoodles  vanilla  vanillaicecream  \\\n",
            "0      0             0          0  ...            0        0                0   \n",
            "1      0             0          0  ...            0        0                0   \n",
            "2      0             0          0  ...            0        0                0   \n",
            "3      0             0          0  ...            0        0                0   \n",
            "4      1             0          0  ...            0        0                0   \n",
            "\n",
            "   vegan  vegetables  vegetarian  warm  whippedcream  winter  yeastdough  \n",
            "0      1           0           1     0             0       0           0  \n",
            "1      0           0           0     0             0       0           0  \n",
            "2      0           1           0     0             0       0           0  \n",
            "3      0           0           0     0             0       0           0  \n",
            "4      0           0           0     0             0       1           0  \n",
            "\n",
            "[5 rows x 298 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_10066/2720197081.py:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  features.insert(1, \"bias\", 1)\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load files\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "tags = pd.read_csv(\"recipe-tags.tsv\", sep=\"\\t\")\n",
        "\n",
        "# One-hot encode tags\n",
        "tag_matrix = (\n",
        "    tags\n",
        "    .assign(value=1)\n",
        "    .pivot_table(\n",
        "        index=\"recipe_slug\",\n",
        "        columns=\"recipe_tag\",\n",
        "        values=\"value\",\n",
        "        fill_value=0\n",
        "    )\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Merge with ratings to guarantee same order\n",
        "features = ratings[[\"recipe_slug\"]].merge(tag_matrix, on=\"recipe_slug\", how=\"left\")\n",
        "\n",
        "# Fill any missing tags with 0 (in case a recipe had no tags)\n",
        "tag_cols = features.columns.drop(\"recipe_slug\")\n",
        "features[tag_cols] = features[tag_cols].fillna(0).astype(int)\n",
        "\n",
        "# Add bias column = 1\n",
        "features.insert(1, \"bias\", 1)\n",
        "\n",
        "# Save features.tsv\n",
        "features.to_csv(\"features.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved features.tsv\")\n",
        "print(\"Shape:\", features.shape)\n",
        "print(features.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w63ji-Oi6oH7"
      },
      "source": [
        "Submit \"features.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TeXvznlwJzo"
      },
      "source": [
        "## Part 3: Linear Preference Model\n",
        "\n",
        "Use your feature and rating files to build a ridge regression model with ridge regression's regularization parameter $\\alpha$ set to 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVlUnVv4oDIk"
      },
      "source": [
        "Hint: If you are using scikit-learn modeling classes, you should use `fit_intercept=False` since that intercept value will be redundant with the bias coefficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrBu-z7A45W"
      },
      "source": [
        "Hint: The estimate component of the bounds should match the previous estimate, so you should be able to just focus on the variance component of the bounds now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dxtiRunPwPYz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.24.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from scikit-learn) (2.4.2)\n",
            "Collecting scipy>=1.10.0 (from scikit-learn)\n",
            "  Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting joblib>=1.3.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.8.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
            "Downloading scipy-1.17.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (35.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.0/35.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [scikit-learn][0m [scikit-learn]\n",
            "\u001b[1A\u001b[2KSuccessfully installed joblib-1.5.3 scikit-learn-1.8.0 scipy-1.17.0 threadpoolctl-3.6.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "X shape: (100, 297)\n",
            "Theta shape: (297,)\n",
            "First 5 predictions: [0.273263   0.26744858 0.24711258 0.46900734 0.99093602]\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "%pip install scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Load data\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Sanity: ensure same order\n",
        "assert (features[\"recipe_slug\"].values == ratings[\"recipe_slug\"].values).all()\n",
        "\n",
        "# Build X and y\n",
        "X = features.drop(columns=[\"recipe_slug\"]).values   # includes bias column\n",
        "y = ratings[\"rating\"].values\n",
        "\n",
        "model = Ridge(alpha=1.0, fit_intercept=False)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Coefficients (theta-hat)\n",
        "theta_hat = model.coef_\n",
        "\n",
        "# Predicted preferences\n",
        "y_hat = model.predict(X)\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"Theta shape:\", theta_hat.shape)\n",
        "print(\"First 5 predictions:\", y_hat[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fw9LaHF_8tsA"
      },
      "source": [
        "Save the coefficients of this model in a file \"model.tsv\" with columns \"recipe_tag\" and \"coefficient\".\n",
        "Do not add anything for the `intercept_` attribute of a scikit-learn model; this will be covered by the coefficient for the bias column added in part 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fiMBlU4L8uSR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model.tsv\n",
            "  recipe_tag  coefficient\n",
            "0       bias     0.307752\n",
            "1    alfredo    -0.007444\n",
            "2     almond     0.057050\n",
            "3   american     0.017860\n",
            "4  appetizer     0.048371\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Reload features to get column names in the correct order\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Get feature names (excluding recipe_slug)\n",
        "feature_names = features.drop(columns=[\"recipe_slug\"]).columns.tolist()\n",
        "\n",
        "# Coefficients from Part 3 model\n",
        "coefs = model.coef_\n",
        "\n",
        "# Sanity check\n",
        "assert len(feature_names) == len(coefs)\n",
        "\n",
        "# Build model.tsv\n",
        "model_df = pd.DataFrame({\n",
        "    \"recipe_tag\": feature_names,\n",
        "    \"coefficient\": coefs\n",
        "})\n",
        "\n",
        "# Save\n",
        "model_df.to_csv(\"model.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved model.tsv\")\n",
        "print(model_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86uS_zZ0wQxC"
      },
      "source": [
        "Submit \"model.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1Nfs7zCsDpj"
      },
      "source": [
        "## Part 4: Recipe Estimates\n",
        "\n",
        "Use the recipe model to estimate the score of every recipe.\n",
        "Save these estimates to a file \"estimates.tsv\" with columns recipe_slug and score_estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pIClPwYVso5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved estimates.tsv\n",
            "        recipe_slug  score_estimate\n",
            "0           falafel        0.273263\n",
            "1        spamburger        0.267449\n",
            "2  bacon-fried-rice        0.247113\n",
            "3   chicken-fingers        0.469007\n",
            "4       apple-crisp        0.990936\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load features (for slugs + X)\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Build X in the same way as training\n",
        "X = features.drop(columns=[\"recipe_slug\"]).values\n",
        "\n",
        "# Predict scores using the ridge model from Part 3\n",
        "score_estimate = model.predict(X)\n",
        "\n",
        "# Build estimates.tsv\n",
        "estimates = pd.DataFrame({\n",
        "    \"recipe_slug\": features[\"recipe_slug\"],\n",
        "    \"score_estimate\": score_estimate\n",
        "})\n",
        "\n",
        "# Save\n",
        "estimates.to_csv(\"estimates.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved estimates.tsv\")\n",
        "print (estimates.head()) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5t3uSE_srMA"
      },
      "source": [
        "Submit \"estimates.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTBplNhRst8q"
      },
      "source": [
        "## Part 5: LinUCB Bounds\n",
        "\n",
        "Calculate the upper bounds of LinUCB using data corresponding to trying every recipe once and receiving the rating in \"ratings.tsv\" as the reward.\n",
        "Keep the ridge regression regularization parameter at 1, and set LinUCB's $\\alpha$ parameter to 2.\n",
        "Save these upper bounds to a file \"bounds.tsv\" with columns recipe_slug and score_bound."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kY7aWD_PuP0W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved bounds.tsv\n",
            "        recipe_slug  score_bound\n",
            "0           falafel     2.039518\n",
            "1        spamburger     2.161785\n",
            "2  bacon-fried-rice     2.113269\n",
            "3   chicken-fingers     2.263123\n",
            "4       apple-crisp     2.767278\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Sanity: same order\n",
        "assert (features[\"recipe_slug\"].values == ratings[\"recipe_slug\"].values).all()\n",
        "\n",
        "# Build X and y\n",
        "X = features.drop(columns=[\"recipe_slug\"]).values\n",
        "y = ratings[\"rating\"].values\n",
        "\n",
        "d = X.shape[1]\n",
        "lambda_ridge = 1.0     # ridge regularization\n",
        "alpha_ucb = 2.0       # LinUCB exploration parameter\n",
        "\n",
        "# Initialize A and b (LinUCB / ridge)\n",
        "A = lambda_ridge * np.eye(d)\n",
        "b = np.zeros(d)\n",
        "\n",
        "# \"Try every recipe once\" and update A, b\n",
        "for i in range(len(X)):\n",
        "    x = X[i]\n",
        "    r = y[i]\n",
        "    A += np.outer(x, x)\n",
        "    b += r * x\n",
        "\n",
        "# Compute A_inv and theta_hat\n",
        "A_inv = np.linalg.inv(A)\n",
        "theta_hat = A_inv @ b\n",
        "\n",
        "# Compute LinUCB upper bounds for each recipe\n",
        "score_bound = []\n",
        "for i in range(len(X)):\n",
        "    x = X[i]\n",
        "    mean = x @ theta_hat\n",
        "    var = np.sqrt(x @ A_inv @ x)\n",
        "    ucb = mean + alpha_ucb * var\n",
        "    score_bound.append(ucb)\n",
        "\n",
        "bounds = pd.DataFrame({\n",
        "    \"recipe_slug\": features[\"recipe_slug\"],\n",
        "    \"score_bound\": score_bound\n",
        "})\n",
        "\n",
        "# Save\n",
        "bounds.to_csv(\"bounds.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved bounds.tsv\")\n",
        "print(bounds.head()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ4RPppFvG-S"
      },
      "source": [
        "Submit \"bounds.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfazOSWlwYsP"
      },
      "source": [
        "## Part 6: Make Online Recommendations\n",
        "\n",
        "Implement LinUCB to make 100 recommendations starting with no data and using the same parameters as in part 5.\n",
        "One recommendation should be made at a time and you can break ties arbitrarily.\n",
        "After each recommendation, use the rating from part 1 as the reward to update the LinUCB data.\n",
        "Record the recommendations made in a file \"recommendations.tsv\" with columns \"recipe_slug\", \"score_bound\", and \"reward\".\n",
        "The rows in this file should be in the same order as the recommendations were made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hint: do not remove recipes after each recommendation.\n",
        "Repeating recommendations is expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hQ7r45B7wm4v"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved recommendations.tsv\n",
            "        recipe_slug  score_bound  reward\n",
            "0     apple-crumble     7.483315    1.00\n",
            "1             ramen     7.270093    0.00\n",
            "2       quesadillas     7.235617    0.00\n",
            "3     ma-la-chicken     7.095599    0.00\n",
            "4  pain-au-chocolat     6.936422    0.75\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "features = pd.read_csv(\"features.tsv\", sep=\"\\t\")\n",
        "ratings = pd.read_csv(\"ratings.tsv\", sep=\"\\t\")\n",
        "\n",
        "# Sanity: same order\n",
        "assert (features[\"recipe_slug\"].values == ratings[\"recipe_slug\"].values).all()\n",
        "\n",
        "X = features.drop(columns=[\"recipe_slug\"]).values\n",
        "y = ratings[\"rating\"].values\n",
        "slugs = features[\"recipe_slug\"].values\n",
        "\n",
        "d = X.shape[1]\n",
        "lambda_ridge = 1.0\n",
        "alpha_ucb = 2.0\n",
        "T = 100\n",
        "\n",
        "# Initialize LinUCB state (no data)\n",
        "A = lambda_ridge * np.eye(d)\n",
        "b = np.zeros(d)\n",
        "\n",
        "rows = []\n",
        "\n",
        "for t in range(T):\n",
        "    A_inv = np.linalg.inv(A)\n",
        "    theta_hat = A_inv @ b\n",
        "\n",
        "    # Compute UCB for all recipes\n",
        "    bounds = []\n",
        "    for i in range(len(X)):\n",
        "        x = X[i]\n",
        "        mean = x @ theta_hat\n",
        "        var = np.sqrt(x @ A_inv @ x)\n",
        "        ucb = mean + alpha_ucb * var\n",
        "        bounds.append(ucb)\n",
        "\n",
        "    bounds = np.array(bounds)\n",
        "\n",
        "    # Pick best recipe (ties arbitrary)\n",
        "    i_star = int(np.argmax(bounds))\n",
        "\n",
        "    # Observe reward\n",
        "    reward = y[i_star]\n",
        "    x_star = X[i_star]\n",
        "\n",
        "    # Record\n",
        "    rows.append({\n",
        "        \"recipe_slug\": slugs[i_star],\n",
        "        \"score_bound\": bounds[i_star],\n",
        "        \"reward\": reward\n",
        "    })\n",
        "\n",
        "    # Update LinUCB\n",
        "    A += np.outer(x_star, x_star)\n",
        "    b += reward * x_star\n",
        "\n",
        "recommendations = pd.DataFrame(rows)\n",
        "recommendations.to_csv(\"recommendations.tsv\", sep=\"\\t\", index=False)\n",
        "\n",
        "print(\"Saved recommendations.tsv\")\n",
        "print(recommendations.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23jv0cD0woSt"
      },
      "source": [
        "Submit \"recommendations.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi8lV2pbvWMs"
      },
      "source": [
        "## Part 7: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved acknowledgments.txt\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "content = \"\"\"I used ChatGPT (OpenAI) as a support tool to help clarify assignment requirements, debug errors in my Python code, and sanity-check intermediate results while implementing ridge regression and LinUCB.\n",
        "\n",
        "Libraries used beyond standard Python:\n",
        "- pandas: for loading, reshaping, and saving TSV files\n",
        "- numpy: for matrix operations and linear algebra\n",
        "- scikit-learn: for ridge regression (Part 3)\n",
        "\n",
        "No other outside sources were used.\n",
        "\"\"\"\n",
        "\n",
        "Path(\"acknowledgments.txt\").write_text(content)\n",
        "print(\"Saved acknowledgments.txt\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuNJe62UxCoH"
      },
      "source": [
        "Submit \"acknowledgments.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smsTLuFcvR-I"
      },
      "source": [
        "## Part 8: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cgzHyF7wxpr"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
